from fastapi import FastAPI, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import io, base64, re, logging
from openai import OpenAI

app = FastAPI()

# Logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# CORS
origins = ["http://localhost:3000", "http://127.0.0.1:3000"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI client
client = OpenAI(api_key="Enter your API key here")  

uploaded_df = None
qa_history = []

@app.post("/upload")
async def upload_file(file: UploadFile):
    global uploaded_df
    try:
        uploaded_df = pd.read_csv(file.file)
        logging.info(f"Uploaded file shape: {uploaded_df.shape}")
        return {"status": "File uploaded successfully!", "columns": uploaded_df.columns.tolist()}
    except Exception as e:
        logging.error(f"Upload failed: {e}")
        return JSONResponse(status_code=400, content={"error": str(e)})

@app.post("/ask")
async def ask_question(question: str = Form(...), chart: str = Form(default="no")):
    global uploaded_df, qa_history
    if uploaded_df is None:
        return JSONResponse(status_code=400, content={"error": "No data uploaded yet."})

    q_lower = question.lower()

    # Hardcoded special case
    if "count" in q_lower and ("records" in q_lower or "rows" in q_lower):
        answer = int(len(uploaded_df))
        update_qa_history(question, answer)
        return {"answer": answer, "chart": None, "history": qa_history}

    try:
        prompt = (
            f"Given this DataFrame preview:\n\n{uploaded_df.head(5)}\n\n"
            f"Generate pandas code to answer: '{question}'. "
            f"Assign the final result to a variable named 'output'. "
            f"If a plot is used, assign the figure to 'output'."
        )

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Youâ€™re a data analyst and pandas expert. Output only pandas code."},
                {"role": "user", "content": prompt}
            ]
        )

        generated_code = response.choices[0].message.content.strip()
        logging.info(f"Generated code: {generated_code}")

        if generated_code.startswith("```"):
            generated_code = "\n".join(generated_code.split("\n")[1:-1])

        # Safe execution
        import builtins
        allowed = ['abs', 'all', 'any', 'bool', 'dict', 'enumerate', 'float', 'format',
                   'int', 'len', 'list', 'map', 'max', 'min', 'next', 'range', 'round',
                   'str', 'sum', 'tuple', 'zip', '__import__']
        safe_builtins = {k: getattr(builtins, k) for k in allowed}
        safe_globals = {"__builtins__": safe_builtins}
        safe_locals = {"df": uploaded_df.copy(), "pd": pd, "np": np, "plt": plt, "output": None}

        exec(generated_code, safe_globals, safe_locals)
        result = safe_locals.get("output")

        if result is None:
            return JSONResponse(status_code=400, content={"error": "No output generated by GPT."})

        chart_data = None
        if "Figure" in str(type(result)) and chart.lower() == "yes":
            buf = io.BytesIO()
            result.savefig(buf, format="png")
            buf.seek(0)
            chart_data = f"data:image/png;base64,{base64.b64encode(buf.read()).decode()}"
            plt.close(result)
            result = "Chart generated successfully."

        if isinstance(result, (pd.DataFrame, pd.Series)):
            result = result.reset_index().replace({np.nan: None}).to_dict(orient="records")
        elif isinstance(result, (np.integer, np.floating)):
            result = float(result)
        elif not isinstance(result, (str, int, float, list, dict)):
            result = str(result)

        update_qa_history(question, result)
        return {"answer": result, "chart": chart_data, "history": qa_history}

    except Exception as e:
        logging.error(f"Error in /ask: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

def update_qa_history(question, answer):
    global qa_history
    def convert(v):
        if isinstance(v, (np.integer, np.int64)): return int(v)
        if isinstance(v, (np.floating, np.float64)): return float(v)
        return v

    if isinstance(answer, list):
        answer = [{k: convert(v) for k, v in item.items()} for item in answer]
    elif isinstance(answer, dict):
        answer = {k: convert(v) for k, v in answer.items()}
    qa_history.append({"question": question, "answer": answer})
    if len(qa_history) > 5:
        qa_history.pop(0)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("smart_analyst:app", host="127.0.0.1", port=8000, reload=True)
